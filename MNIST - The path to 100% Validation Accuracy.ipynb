{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import image_files\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from random import seed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders import generate_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from main import MNISTNet, CNNNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(6)\n",
    "torch.manual_seed(6)\n",
    "np.random.seed(6)\n",
    "\n",
    "device=1\n",
    "dtag=f'cuda:{device}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = generate_dataset(image_files[3], image_files[2])\n",
    "test_images = generate_dataset(image_files[1], image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "60000\n",
      "\n",
      "Testing Dataset\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset')\n",
    "print(len(train_images))\n",
    "# print(train_images[0][0])\n",
    "# print(train_images[0][1])\n",
    "\n",
    "print('\\nTesting Dataset')\n",
    "print(len(test_images))\n",
    "# print(test_images[0][0])\n",
    "# print(test_images[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (8): ReLU()\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (12): ReLU()\n",
       "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=576, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNNet()\n",
    "model.to(dtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_images, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_images, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = CrossEntropyLoss(torch.Tensor(\n",
    "    [0.05172413793103448, 0.05172413793103448, 0.06896551724137931, 0.10344827586206896, 0.10344827586206896, 0.13793103448275862, 0.1206896551724138, 0.1206896551724138, 0.10344827586206896, 0.13793103448275862]\n",
    ").to(dtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-84b6a4e98e93>:52: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  incorrect = tuple((correct == 0).nonzero())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.1522, Val Loss: 0.0335, acc = 0.989000, miss=110\n",
      "Epoch: 1, Train Loss: 0.0495, Val Loss: 0.0527, acc = 0.982400, miss=176\n",
      "Epoch: 2, Train Loss: 0.0364, Val Loss: 0.0320, acc = 0.990700, miss=93\n",
      "Epoch: 3, Train Loss: 0.0334, Val Loss: 0.0259, acc = 0.992700, miss=73\n",
      "Epoch: 4, Train Loss: 0.0271, Val Loss: 0.0320, acc = 0.989000, miss=110\n",
      "Epoch: 5, Train Loss: 0.0254, Val Loss: 0.0246, acc = 0.993200, miss=68\n",
      "Epoch: 6, Train Loss: 0.0202, Val Loss: 0.0260, acc = 0.991300, miss=87\n",
      "Epoch: 7, Train Loss: 0.0200, Val Loss: 0.0314, acc = 0.991400, miss=86\n",
      "Epoch: 8, Train Loss: 0.0178, Val Loss: 0.0279, acc = 0.992900, miss=71\n",
      "Epoch: 9, Train Loss: 0.0186, Val Loss: 0.0282, acc = 0.992900, miss=71\n",
      "Epoch: 10, Train Loss: 0.0154, Val Loss: 0.0318, acc = 0.990900, miss=91\n",
      "Epoch: 11, Train Loss: 0.0137, Val Loss: 0.0365, acc = 0.990300, miss=97\n",
      "Epoch: 12, Train Loss: 0.0140, Val Loss: 0.0340, acc = 0.990900, miss=91\n",
      "Epoch: 13, Train Loss: 0.0141, Val Loss: 0.0299, acc = 0.993600, miss=64\n",
      "Epoch: 14, Train Loss: 0.0104, Val Loss: 0.0376, acc = 0.991200, miss=88\n",
      "value   actuals    guesses   total\n",
      "  0:       2          4        6\n",
      "  1:       1          2        3\n",
      "  2:       2          4        6\n",
      "  3:       3          3        6\n",
      "  4:       1          4        5\n",
      "  5:       3          4        7\n",
      "  6:       5          2        7\n",
      "  7:       4          2        6\n",
      "  8:       5          1        6\n",
      "  9:       5          5        10\n",
      "new_weights:\n",
      "[0.0967741935483871, 0.04838709677419355, 0.0967741935483871, 0.0967741935483871, 0.08064516129032258, 0.11290322580645161, 0.11290322580645161, 0.0967741935483871, 0.0967741935483871, 0.16129032258064516]\n",
      "Epoch: 0, Train Loss: 0.0125, Val Loss: 0.0449, acc = 0.992500, miss=75\n",
      "Epoch: 1, Train Loss: 0.0127, Val Loss: 0.0499, acc = 0.987800, miss=122\n",
      "Epoch: 2, Train Loss: 0.0115, Val Loss: 0.0408, acc = 0.990300, miss=97\n",
      "Epoch: 3, Train Loss: 0.0090, Val Loss: 0.0376, acc = 0.993900, miss=61\n",
      "Epoch: 4, Train Loss: 0.0104, Val Loss: 0.0318, acc = 0.993700, miss=63\n",
      "Epoch: 5, Train Loss: 0.0078, Val Loss: 0.0448, acc = 0.991600, miss=84\n",
      "Epoch: 6, Train Loss: 0.0100, Val Loss: 0.0377, acc = 0.993300, miss=67\n",
      "Epoch: 7, Train Loss: 0.0108, Val Loss: 0.0394, acc = 0.992600, miss=74\n",
      "Epoch: 8, Train Loss: 0.0064, Val Loss: 0.0416, acc = 0.991900, miss=81\n",
      "Epoch: 9, Train Loss: 0.0100, Val Loss: 0.0403, acc = 0.992500, miss=75\n",
      "Epoch: 10, Train Loss: 0.0073, Val Loss: 0.0481, acc = 0.989300, miss=107\n",
      "Epoch: 11, Train Loss: 0.0100, Val Loss: 0.0432, acc = 0.992800, miss=72\n",
      "Epoch: 12, Train Loss: 0.0077, Val Loss: 0.0359, acc = 0.992700, miss=73\n",
      "Epoch: 13, Train Loss: 0.0076, Val Loss: 0.0457, acc = 0.992600, miss=74\n",
      "Epoch: 14, Train Loss: 0.0057, Val Loss: 0.0432, acc = 0.992900, miss=71\n",
      "Epoch: 15, Train Loss: 0.0073, Val Loss: 0.0394, acc = 0.992900, miss=71\n",
      "Epoch: 16, Train Loss: 0.0062, Val Loss: 0.0402, acc = 0.992700, miss=73\n",
      "Epoch: 17, Train Loss: 0.0064, Val Loss: 0.0405, acc = 0.992700, miss=73\n",
      "Epoch: 18, Train Loss: 0.0063, Val Loss: 0.0432, acc = 0.992300, miss=77\n",
      "Epoch: 19, Train Loss: 0.0071, Val Loss: 0.0565, acc = 0.989800, miss=102\n",
      "Epoch: 20, Train Loss: 0.0059, Val Loss: 0.0468, acc = 0.989900, miss=101\n",
      "Epoch: 21, Train Loss: 0.0026, Val Loss: 0.0486, acc = 0.992600, miss=74\n",
      "Epoch: 22, Train Loss: 0.0096, Val Loss: 0.0516, acc = 0.991700, miss=83\n",
      "Epoch: 23, Train Loss: 0.0044, Val Loss: 0.0386, acc = 0.994300, miss=57\n",
      "Epoch: 24, Train Loss: 0.0064, Val Loss: 0.0447, acc = 0.992900, miss=71\n",
      "Epoch: 25, Train Loss: 0.0042, Val Loss: 0.0615, acc = 0.991600, miss=84\n",
      "Epoch: 26, Train Loss: 0.0058, Val Loss: 0.0475, acc = 0.991500, miss=85\n",
      "Epoch: 27, Train Loss: 0.0049, Val Loss: 0.0371, acc = 0.993500, miss=65\n",
      "Epoch: 28, Train Loss: 0.0042, Val Loss: 0.0706, acc = 0.989900, miss=101\n",
      "Epoch: 29, Train Loss: 0.0043, Val Loss: 0.0574, acc = 0.991700, miss=83\n",
      "Epoch: 30, Train Loss: 0.0053, Val Loss: 0.0478, acc = 0.991600, miss=84\n",
      "Epoch: 31, Train Loss: 0.0026, Val Loss: 0.0748, acc = 0.990900, miss=91\n",
      "Epoch: 32, Train Loss: 0.0072, Val Loss: 0.0496, acc = 0.991300, miss=87\n",
      "Epoch: 33, Train Loss: 0.0041, Val Loss: 0.0524, acc = 0.993300, miss=67\n",
      "Epoch: 34, Train Loss: 0.0040, Val Loss: 0.0468, acc = 0.992900, miss=71\n",
      "Epoch: 35, Train Loss: 0.0054, Val Loss: 0.0554, acc = 0.992200, miss=78\n",
      "Epoch: 36, Train Loss: 0.0046, Val Loss: 0.0407, acc = 0.993700, miss=63\n",
      "Epoch: 37, Train Loss: 0.0023, Val Loss: 0.0675, acc = 0.991600, miss=84\n",
      "Epoch: 38, Train Loss: 0.0036, Val Loss: 0.0564, acc = 0.991900, miss=81\n",
      "Epoch: 39, Train Loss: 0.0067, Val Loss: 0.0559, acc = 0.992100, miss=79\n",
      "Epoch: 40, Train Loss: 0.0027, Val Loss: 0.0598, acc = 0.992800, miss=72\n",
      "Epoch: 41, Train Loss: 0.0016, Val Loss: 0.0467, acc = 0.993300, miss=67\n",
      "Epoch: 42, Train Loss: 0.0073, Val Loss: 0.0697, acc = 0.989800, miss=102\n",
      "Epoch: 43, Train Loss: 0.0023, Val Loss: 0.0559, acc = 0.992700, miss=73\n",
      "Epoch: 44, Train Loss: 0.0044, Val Loss: 0.0516, acc = 0.991700, miss=83\n",
      "Epoch: 45, Train Loss: 0.0050, Val Loss: 0.0548, acc = 0.991700, miss=83\n",
      "Epoch: 46, Train Loss: 0.0031, Val Loss: 0.0716, acc = 0.990400, miss=96\n",
      "Epoch: 47, Train Loss: 0.0029, Val Loss: 0.0552, acc = 0.991800, miss=82\n",
      "Epoch: 48, Train Loss: 0.0028, Val Loss: 0.0506, acc = 0.992500, miss=75\n",
      "Epoch: 49, Train Loss: 0.0044, Val Loss: 0.0514, acc = 0.991600, miss=84\n",
      "Epoch: 50, Train Loss: 0.0034, Val Loss: 0.0484, acc = 0.994000, miss=60\n",
      "Epoch: 51, Train Loss: 0.0035, Val Loss: 0.0525, acc = 0.991100, miss=89\n",
      "Epoch: 52, Train Loss: 0.0032, Val Loss: 0.0449, acc = 0.992700, miss=73\n",
      "Epoch: 53, Train Loss: 0.0006, Val Loss: 0.0446, acc = 0.993300, miss=67\n",
      "Epoch: 54, Train Loss: 0.0047, Val Loss: 0.0793, acc = 0.990300, miss=97\n",
      "Epoch: 55, Train Loss: 0.0031, Val Loss: 0.0539, acc = 0.992800, miss=72\n",
      "Epoch: 56, Train Loss: 0.0003, Val Loss: 0.0639, acc = 0.992900, miss=71\n",
      "Epoch: 57, Train Loss: 0.0051, Val Loss: 0.0565, acc = 0.993200, miss=68\n",
      "Epoch: 58, Train Loss: 0.0038, Val Loss: 0.0532, acc = 0.993300, miss=67\n",
      "Epoch: 59, Train Loss: 0.0023, Val Loss: 0.0485, acc = 0.993700, miss=63\n",
      "Epoch: 60, Train Loss: 0.0026, Val Loss: 0.0721, acc = 0.990800, miss=92\n",
      "Epoch: 61, Train Loss: 0.0023, Val Loss: 0.0633, acc = 0.992900, miss=71\n",
      "Epoch: 62, Train Loss: 0.0044, Val Loss: 0.0658, acc = 0.992300, miss=77\n",
      "Epoch: 63, Train Loss: 0.0032, Val Loss: 0.0516, acc = 0.993200, miss=68\n",
      "Epoch: 64, Train Loss: 0.0018, Val Loss: 0.0594, acc = 0.992000, miss=80\n",
      "Epoch: 65, Train Loss: 0.0043, Val Loss: 0.0464, acc = 0.993800, miss=62\n",
      "Epoch: 66, Train Loss: 0.0015, Val Loss: 0.0564, acc = 0.993200, miss=68\n",
      "Epoch: 67, Train Loss: 0.0036, Val Loss: 0.0493, acc = 0.992200, miss=78\n",
      "Epoch: 68, Train Loss: 0.0032, Val Loss: 0.0503, acc = 0.993500, miss=65\n",
      "Epoch: 69, Train Loss: 0.0027, Val Loss: 0.0720, acc = 0.990600, miss=94\n",
      "Epoch: 70, Train Loss: 0.0031, Val Loss: 0.0649, acc = 0.992300, miss=77\n",
      "Epoch: 71, Train Loss: 0.0015, Val Loss: 0.0482, acc = 0.993300, miss=67\n",
      "Epoch: 72, Train Loss: 0.0018, Val Loss: 0.0741, acc = 0.992100, miss=79\n",
      "Epoch: 73, Train Loss: 0.0028, Val Loss: 0.0774, acc = 0.992200, miss=78\n",
      "Epoch: 74, Train Loss: 0.0028, Val Loss: 0.0735, acc = 0.991700, miss=83\n",
      "Epoch: 75, Train Loss: 0.0043, Val Loss: 0.0534, acc = 0.993900, miss=61\n",
      "Epoch: 76, Train Loss: 0.0019, Val Loss: 0.0560, acc = 0.993300, miss=67\n",
      "Epoch: 77, Train Loss: 0.0019, Val Loss: 0.0495, acc = 0.994700, miss=53\n",
      "Epoch: 78, Train Loss: 0.0001, Val Loss: 0.0540, acc = 0.994000, miss=60\n",
      "Epoch: 79, Train Loss: 0.0000, Val Loss: 0.0534, acc = 0.993900, miss=61\n",
      "Epoch: 80, Train Loss: 0.0000, Val Loss: 0.0537, acc = 0.994100, miss=59\n",
      "Epoch: 81, Train Loss: 0.0000, Val Loss: 0.0542, acc = 0.994100, miss=59\n",
      "Epoch: 82, Train Loss: 0.0000, Val Loss: 0.0549, acc = 0.994100, miss=59\n",
      "Epoch: 83, Train Loss: 0.0000, Val Loss: 0.0557, acc = 0.994300, miss=57\n",
      "Epoch: 84, Train Loss: 0.0000, Val Loss: 0.0566, acc = 0.994400, miss=56\n",
      "Epoch: 85, Train Loss: 0.0000, Val Loss: 0.0576, acc = 0.994400, miss=56\n",
      "Epoch: 86, Train Loss: 0.0000, Val Loss: 0.0588, acc = 0.994400, miss=56\n",
      "Epoch: 87, Train Loss: 0.0000, Val Loss: 0.0600, acc = 0.994400, miss=56\n",
      "Epoch: 88, Train Loss: 0.0000, Val Loss: 0.0613, acc = 0.994400, miss=56\n",
      "Epoch: 89, Train Loss: 0.0000, Val Loss: 0.0626, acc = 0.994400, miss=56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Train Loss: 0.0000, Val Loss: 0.0639, acc = 0.994500, miss=55\n",
      "Epoch: 91, Train Loss: 0.0000, Val Loss: 0.0652, acc = 0.994500, miss=55\n",
      "Epoch: 92, Train Loss: 0.0000, Val Loss: 0.0666, acc = 0.994500, miss=55\n",
      "Epoch: 93, Train Loss: 0.0000, Val Loss: 0.0679, acc = 0.994500, miss=55\n",
      "Epoch: 94, Train Loss: 0.0000, Val Loss: 0.0693, acc = 0.994500, miss=55\n",
      "Epoch: 95, Train Loss: 0.0000, Val Loss: 0.0706, acc = 0.994400, miss=56\n",
      "Epoch: 96, Train Loss: 0.0000, Val Loss: 0.0719, acc = 0.994400, miss=56\n",
      "Epoch: 97, Train Loss: 0.0000, Val Loss: 0.0732, acc = 0.994400, miss=56\n",
      "Epoch: 98, Train Loss: 0.0000, Val Loss: 0.0746, acc = 0.994400, miss=56\n",
      "Epoch: 99, Train Loss: 0.0000, Val Loss: 0.0760, acc = 0.994400, miss=56\n",
      "Epoch: 100, Train Loss: 0.0000, Val Loss: 0.0770, acc = 0.994300, miss=57\n",
      "Epoch: 101, Train Loss: 0.0000, Val Loss: 0.0780, acc = 0.994400, miss=56\n",
      "Epoch: 102, Train Loss: 0.0000, Val Loss: 0.0789, acc = 0.994400, miss=56\n",
      "Epoch: 103, Train Loss: 0.0000, Val Loss: 0.0796, acc = 0.994500, miss=55\n",
      "Epoch: 104, Train Loss: 0.0000, Val Loss: 0.0806, acc = 0.994500, miss=55\n",
      "Epoch: 105, Train Loss: 0.0000, Val Loss: 0.0816, acc = 0.994700, miss=53\n",
      "Epoch: 106, Train Loss: 0.0000, Val Loss: 0.0832, acc = 0.994600, miss=54\n",
      "Epoch: 107, Train Loss: 0.0000, Val Loss: 0.0846, acc = 0.994600, miss=54\n",
      "Epoch: 108, Train Loss: 0.0000, Val Loss: 0.0863, acc = 0.994500, miss=55\n",
      "Epoch: 109, Train Loss: 0.0000, Val Loss: 0.0883, acc = 0.994700, miss=53\n",
      "Epoch: 110, Train Loss: 0.0000, Val Loss: 0.0907, acc = 0.994700, miss=53\n",
      "Epoch: 111, Train Loss: 0.0000, Val Loss: 0.0931, acc = 0.994600, miss=54\n",
      "Epoch: 112, Train Loss: 0.0000, Val Loss: 0.0956, acc = 0.994600, miss=54\n",
      "Epoch: 113, Train Loss: 0.0000, Val Loss: 0.0979, acc = 0.994600, miss=54\n",
      "Epoch: 114, Train Loss: 0.0000, Val Loss: 0.1002, acc = 0.994700, miss=53\n",
      "Epoch: 115, Train Loss: 0.0000, Val Loss: 0.1023, acc = 0.994600, miss=54\n",
      "Epoch: 116, Train Loss: 0.0000, Val Loss: 0.1042, acc = 0.994600, miss=54\n",
      "Epoch: 117, Train Loss: 0.0000, Val Loss: 0.1061, acc = 0.994600, miss=54\n",
      "Epoch: 118, Train Loss: 0.0000, Val Loss: 0.1079, acc = 0.994600, miss=54\n",
      "Epoch: 119, Train Loss: 0.0000, Val Loss: 0.1095, acc = 0.994600, miss=54\n",
      "Epoch: 120, Train Loss: 0.0000, Val Loss: 0.1111, acc = 0.994600, miss=54\n",
      "Epoch: 121, Train Loss: 0.0000, Val Loss: 0.1126, acc = 0.994500, miss=55\n",
      "Epoch: 122, Train Loss: 0.0000, Val Loss: 0.1141, acc = 0.994500, miss=55\n",
      "Epoch: 123, Train Loss: 0.0000, Val Loss: 0.1155, acc = 0.994500, miss=55\n",
      "Epoch: 124, Train Loss: 0.0000, Val Loss: 0.1168, acc = 0.994400, miss=56\n",
      "Epoch: 125, Train Loss: 0.0000, Val Loss: 0.1181, acc = 0.994400, miss=56\n",
      "Epoch: 126, Train Loss: 0.0000, Val Loss: 0.1192, acc = 0.994400, miss=56\n",
      "Epoch: 127, Train Loss: 0.0000, Val Loss: 0.1204, acc = 0.994300, miss=57\n",
      "Epoch: 128, Train Loss: 0.0000, Val Loss: 0.1215, acc = 0.994300, miss=57\n",
      "Epoch: 129, Train Loss: 0.0000, Val Loss: 0.1225, acc = 0.994300, miss=57\n",
      "Epoch: 130, Train Loss: 0.0000, Val Loss: 0.1235, acc = 0.994300, miss=57\n",
      "Epoch: 131, Train Loss: 0.0000, Val Loss: 0.1245, acc = 0.994200, miss=58\n",
      "Epoch: 132, Train Loss: 0.0000, Val Loss: 0.1254, acc = 0.994000, miss=60\n",
      "Epoch: 133, Train Loss: 0.0000, Val Loss: 0.1262, acc = 0.994000, miss=60\n",
      "Epoch: 134, Train Loss: 0.0000, Val Loss: 0.1271, acc = 0.994000, miss=60\n",
      "Epoch: 135, Train Loss: 0.0000, Val Loss: 0.1279, acc = 0.994000, miss=60\n",
      "Epoch: 136, Train Loss: 0.0000, Val Loss: 0.1288, acc = 0.994000, miss=60\n",
      "Epoch: 137, Train Loss: 0.0000, Val Loss: 0.1296, acc = 0.994000, miss=60\n",
      "Epoch: 138, Train Loss: 0.0000, Val Loss: 0.1304, acc = 0.994000, miss=60\n",
      "Epoch: 139, Train Loss: 0.0000, Val Loss: 0.1312, acc = 0.994000, miss=60\n",
      "Epoch: 140, Train Loss: 0.0000, Val Loss: 0.1320, acc = 0.993900, miss=61\n",
      "Epoch: 141, Train Loss: 0.0000, Val Loss: 0.1328, acc = 0.993900, miss=61\n",
      "Epoch: 142, Train Loss: 0.0000, Val Loss: 0.1336, acc = 0.993900, miss=61\n",
      "Epoch: 143, Train Loss: 0.0000, Val Loss: 0.1344, acc = 0.993900, miss=61\n",
      "Epoch: 144, Train Loss: 0.0000, Val Loss: 0.1353, acc = 0.993900, miss=61\n",
      "Epoch: 145, Train Loss: 0.0000, Val Loss: 0.1361, acc = 0.993900, miss=61\n",
      "Epoch: 146, Train Loss: 0.0000, Val Loss: 0.1369, acc = 0.993800, miss=62\n",
      "Epoch: 147, Train Loss: 0.0000, Val Loss: 0.1378, acc = 0.993800, miss=62\n",
      "Epoch: 148, Train Loss: 0.0000, Val Loss: 0.1386, acc = 0.993800, miss=62\n",
      "Epoch: 149, Train Loss: 0.0000, Val Loss: 0.1395, acc = 0.993800, miss=62\n",
      "Epoch: 150, Train Loss: 0.0000, Val Loss: 0.1404, acc = 0.993800, miss=62\n",
      "Epoch: 151, Train Loss: 0.0000, Val Loss: 0.1413, acc = 0.993800, miss=62\n",
      "Epoch: 152, Train Loss: 0.0000, Val Loss: 0.1423, acc = 0.993800, miss=62\n",
      "Epoch: 153, Train Loss: 0.0000, Val Loss: 0.1433, acc = 0.993800, miss=62\n",
      "Epoch: 154, Train Loss: 0.0000, Val Loss: 0.1443, acc = 0.993800, miss=62\n",
      "Epoch: 155, Train Loss: 0.0000, Val Loss: 0.1454, acc = 0.993700, miss=63\n",
      "Epoch: 156, Train Loss: 0.0000, Val Loss: 0.1465, acc = 0.993700, miss=63\n",
      "Epoch: 157, Train Loss: 0.0000, Val Loss: 0.1477, acc = 0.993700, miss=63\n",
      "Epoch: 158, Train Loss: 0.0000, Val Loss: 0.1489, acc = 0.993700, miss=63\n",
      "Epoch: 159, Train Loss: 0.0000, Val Loss: 0.1502, acc = 0.993600, miss=64\n",
      "Epoch: 160, Train Loss: 0.0000, Val Loss: 0.1516, acc = 0.993600, miss=64\n",
      "Epoch: 161, Train Loss: 0.0000, Val Loss: 0.1531, acc = 0.993700, miss=63\n",
      "Epoch: 162, Train Loss: 0.0000, Val Loss: 0.1547, acc = 0.993700, miss=63\n",
      "Epoch: 163, Train Loss: 0.0000, Val Loss: 0.1565, acc = 0.993700, miss=63\n",
      "Epoch: 164, Train Loss: 0.0000, Val Loss: 0.1586, acc = 0.993500, miss=65\n",
      "Epoch: 165, Train Loss: 0.0000, Val Loss: 0.1610, acc = 0.993400, miss=66\n",
      "Epoch: 166, Train Loss: 0.0000, Val Loss: 0.1637, acc = 0.993300, miss=67\n",
      "Epoch: 167, Train Loss: 0.0000, Val Loss: 0.1672, acc = 0.993200, miss=68\n",
      "Epoch: 168, Train Loss: 0.0000, Val Loss: 0.1726, acc = 0.992900, miss=71\n",
      "Epoch: 169, Train Loss: 0.0000, Val Loss: 0.1731, acc = 0.993400, miss=66\n",
      "Epoch: 170, Train Loss: 0.0000, Val Loss: 0.1754, acc = 0.993500, miss=65\n",
      "Epoch: 171, Train Loss: 0.0000, Val Loss: 0.1771, acc = 0.993400, miss=66\n",
      "Epoch: 172, Train Loss: 0.0000, Val Loss: 0.1788, acc = 0.993200, miss=68\n",
      "Epoch: 173, Train Loss: 0.0000, Val Loss: 0.1807, acc = 0.993100, miss=69\n",
      "Epoch: 174, Train Loss: 0.0000, Val Loss: 0.1828, acc = 0.993100, miss=69\n",
      "Epoch: 175, Train Loss: 0.0000, Val Loss: 0.1850, acc = 0.993200, miss=68\n",
      "Epoch: 176, Train Loss: 0.0000, Val Loss: 0.1874, acc = 0.993300, miss=67\n",
      "Epoch: 177, Train Loss: 0.0000, Val Loss: 0.1899, acc = 0.993300, miss=67\n",
      "Epoch: 178, Train Loss: 0.0000, Val Loss: 0.1928, acc = 0.993300, miss=67\n",
      "Epoch: 179, Train Loss: 0.0000, Val Loss: 0.1961, acc = 0.993000, miss=70\n",
      "Epoch: 180, Train Loss: 0.0000, Val Loss: 0.1997, acc = 0.993100, miss=69\n",
      "Epoch: 181, Train Loss: 0.0000, Val Loss: 0.2038, acc = 0.993100, miss=69\n",
      "Epoch: 182, Train Loss: 0.0000, Val Loss: 0.2086, acc = 0.993000, miss=70\n",
      "Epoch: 183, Train Loss: 0.0000, Val Loss: 0.2159, acc = 0.992900, miss=71\n",
      "Epoch: 184, Train Loss: 0.0226, Val Loss: 0.0962, acc = 0.992300, miss=77\n",
      "Epoch: 185, Train Loss: 0.0059, Val Loss: 0.0871, acc = 0.993500, miss=65\n",
      "Epoch: 186, Train Loss: 0.0017, Val Loss: 0.0850, acc = 0.992600, miss=74\n",
      "Epoch: 187, Train Loss: 0.0040, Val Loss: 0.0675, acc = 0.993800, miss=62\n",
      "Epoch: 188, Train Loss: 0.0043, Val Loss: 0.0567, acc = 0.993800, miss=62\n",
      "Epoch: 189, Train Loss: 0.0036, Val Loss: 0.0765, acc = 0.992300, miss=77\n",
      "Epoch: 190, Train Loss: 0.0033, Val Loss: 0.0793, acc = 0.992700, miss=73\n",
      "Epoch: 191, Train Loss: 0.0024, Val Loss: 0.0567, acc = 0.994000, miss=60\n",
      "Epoch: 192, Train Loss: 0.0026, Val Loss: 0.0626, acc = 0.993300, miss=67\n",
      "Epoch: 193, Train Loss: 0.0018, Val Loss: 0.0927, acc = 0.990400, miss=96\n",
      "Epoch: 194, Train Loss: 0.0045, Val Loss: 0.0647, acc = 0.993900, miss=61\n",
      "Epoch: 195, Train Loss: 0.0003, Val Loss: 0.0711, acc = 0.993500, miss=65\n",
      "Epoch: 196, Train Loss: 0.0057, Val Loss: 0.0653, acc = 0.994000, miss=60\n",
      "Epoch: 197, Train Loss: 0.0016, Val Loss: 0.0712, acc = 0.994000, miss=60\n",
      "Epoch: 198, Train Loss: 0.0031, Val Loss: 0.0653, acc = 0.992700, miss=73\n",
      "Epoch: 199, Train Loss: 0.0015, Val Loss: 0.0659, acc = 0.993400, miss=66\n",
      "value   actuals    guesses   total\n",
      "  0:       2          2        4\n",
      "  1:       3          2        5\n",
      "  2:       3          2        5\n",
      "  3:       3          3        6\n",
      "  4:       2          3        5\n",
      "  5:       3          4        7\n",
      "  6:       5          3        8\n",
      "  7:       3          2        5\n",
      "  8:       4          5        9\n",
      "  9:       3          5        8\n",
      "new_weights:\n",
      "[0.06451612903225806, 0.08064516129032258, 0.08064516129032258, 0.0967741935483871, 0.08064516129032258, 0.11290322580645161, 0.12903225806451613, 0.08064516129032258, 0.14516129032258066, 0.12903225806451613]\n",
      "Best weights overall: tensor([0.0645, 0.0806, 0.0806, 0.0968, 0.0806, 0.1129, 0.1290, 0.0806, 0.1452,\n",
      "        0.1290], device='cuda:0')\n",
      "Lowest errors overall: 53\n",
      "Best accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "weights = None\n",
    "\n",
    "META_EPOCHS = 2\n",
    "super_best = 1000\n",
    "super_best_weights = weights\n",
    "super_best_model = model_path = './mnist-best.model'\n",
    "super_best_accuracy = 0\n",
    "model = CNNNet()\n",
    "model.to(dtag)\n",
    "EPOCHS = 15\n",
    "try:\n",
    "    for meta in range(META_EPOCHS):\n",
    "        optimizer = Adam(model.parameters(), lr=0.001)\n",
    "        loss_fn = CrossEntropyLoss(weight=weights)\n",
    "\n",
    "\n",
    "        model_path = './mnist.model'\n",
    "        best = 1000\n",
    "        logs = []\n",
    "        verbose = True\n",
    "        mistory = []\n",
    "        best_misses = None\n",
    "        for epoch in range(EPOCHS):\n",
    "            training_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "\n",
    "            for batch in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                _inputs, targets = batch\n",
    "                _inputs = _inputs.unsqueeze(1)\n",
    "                output = model(_inputs.to(dtag))\n",
    "                loss = loss_fn(output, targets.to(dtag))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.data.item() * _inputs.size(0)\n",
    "            training_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_examples = 0\n",
    "            miss_tensors = defaultdict(list)\n",
    "            for batch_no, batch in enumerate(test_dataloader):\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.unsqueeze(1).to(dtag)\n",
    "                targets = targets.to(dtag)\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                valid_loss += loss.data.item() * inputs.size(0)\n",
    "                correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "                incorrect = tuple((correct == 0).nonzero())\n",
    "                for index in incorrect:\n",
    "                    actual = targets[index]\n",
    "                    guess = torch.max(F.softmax(output[index], dim=1), dim=1)[1]\n",
    "                    miss_tensors[(actual.item(), guess.item())].append(inputs[index])\n",
    "                num_correct += torch.sum(correct).item()\n",
    "                num_examples += correct.shape[0]\n",
    "            valid_loss /= len(test_dataloader.dataset)\n",
    "            accuracy = num_correct / num_examples\n",
    "            misses = num_examples-num_correct\n",
    "            if misses < best:\n",
    "                best = misses\n",
    "                best_misses = miss_tensors\n",
    "                torch.save(model, model_path)\n",
    "            if best < super_best:\n",
    "                super_best = best\n",
    "                super_best_weights = weights\n",
    "                torch.save(model, super_best_model)\n",
    "                super_best_accuracy = accuracy\n",
    "            mistory.append(misses)\n",
    "            logs.append('Epoch: {}, Train Loss: {:.4f}, Val Loss: {:.4f}, acc = {:.6f}, miss={}'.format(epoch, training_loss, valid_loss, accuracy, misses))\n",
    "            if verbose:\n",
    "                print(logs[-1])\n",
    "        EPOCHS = 200\n",
    "        if not verbose:\n",
    "            print(logs[-1])\n",
    "\n",
    "        actuals = defaultdict(int)\n",
    "        guesses = defaultdict(int)\n",
    "        for actual, guess in best_misses.keys():\n",
    "            actuals[actual] += 1\n",
    "            guesses[guess] += 1\n",
    "\n",
    "        print('value   actuals    guesses   total')\n",
    "        total = 0\n",
    "        bad = []\n",
    "        for x in range(0, 10):\n",
    "            print(f'  {x}:       {actuals[x]}          {guesses[x]}        {guesses[x] + actuals[x]}')\n",
    "            total += guesses[x] + actuals[x]\n",
    "            bad.append(guesses[x] + actuals[x])\n",
    "\n",
    "        print('new_weights:')\n",
    "        if weights is None:\n",
    "            weights = [0.1]*10\n",
    "        weights = [x/float(total) for index, x in enumerate(bad)]\n",
    "        print(str(weights))\n",
    "        weights = torch.Tensor(weights).to(dtag)\n",
    "except KeyboardInterrupt:\n",
    "    print('Ending early- keyboard interrupt run')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(list(range(1,EPOCHS+1)), mistory)\n",
    "    \n",
    "print('Best weights overall:', weights)\n",
    "print('Lowest errors overall:', super_best)\n",
    "print('Best accuracy:', super_best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = defaultdict(int)\n",
    "guesses = defaultdict(int)\n",
    "for actual, guess in best_misses.keys():\n",
    "    actuals[actual] += 1\n",
    "    guesses[guess] += 1\n",
    "    \n",
    "print('value   actuals    guesses   total')\n",
    "total = 0\n",
    "bad = []\n",
    "for x in range(0, 10):\n",
    "    print(f'  {x}:       {actuals[x]}          {guesses[x]}        {guesses[x] + actuals[x]}')\n",
    "    total += guesses[x] + actuals[x]\n",
    "    bad.append(guesses[x] + actuals[x])\n",
    "\n",
    "print('new_weights:')\n",
    "print(str([x/float(total) for x in bad]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = (2, 7)\n",
    "forward = best_misses[miss]\n",
    "backwards = best_misses[miss[1], miss[0]]\n",
    "longest = len(forward) if len(forward) > len(backwards) else len(backwards)\n",
    "for index in range(longest):\n",
    "    for subindex, x in enumerate(forward):\n",
    "        plt.subplot(longest, 2, subindex*2+1)\n",
    "        plt.imshow(x.cpu().detach().squeeze(0).permute(1,2,0))\n",
    "        if index == 0:\n",
    "            plt.title = f'{miss[0]}->{[miss[1]]}'\n",
    "    for subindex, x in enumerate(backwards):\n",
    "        plt.subplot(longest, 2, subindex*2+2)\n",
    "        plt.imshow(x.cpu().detach().squeeze(0).permute(1,2,0))\n",
    "        if index == 0:\n",
    "            plt.title = f'{miss[1]}->{[miss[0]]}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_fives = []\n",
    "\n",
    "for miss in best_misses:\n",
    "    if miss[0] == 5:\n",
    "        bad_fives.append([miss[0], miss[1], best_misses[miss]])\n",
    "                          \n",
    "for five in sorted(bad_fives, key=lambda x: x[0]*10+x[1]):\n",
    "    print(five)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = list(model.features.modules())[0]\n",
    "target = [x for x in target][3]\n",
    "\n",
    "visualize(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
